# --- 7. Emotion Recognition (Detailed) ---
'''
superb/wav2vec2-base-superb-er ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê°ì • ì¸ì‹
(top_k=3 í›„ë³´ & í™”ìë³„ í™•ë¥  ë¶„í¬ê¹Œì§€)
'''

import librosa
from pyannote.audio import Pipeline
from transformers import pipeline
from collections import defaultdict

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# ì„¤ì •
HF_TOKEN = True  # Hugging Face í† í°ì„ í™˜ê²½ë³€ìˆ˜ë‚˜ ë¡œê·¸ì¸ëœ ìƒíƒœì—ì„œ ì‚¬ìš© ì¤‘ì´ë¼ë©´ True
wav_path = "../data/consult_voice/Training/raw/KtelSpeech_train_D62_wav_0/D62/J93/S00000001/0002.wav"

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 1) í™”ì ë¶„ë¦¬
diar = Pipeline.from_pretrained(
    "pyannote/speaker-diarization",
    use_auth_token=HF_TOKEN
)
diar_result     = diar(wav_path)
speech_timeline = diar_result.get_timeline()

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 2) ê°ì • ë¶„ë¥˜ê¸° ë¡œë“œ
clf = pipeline(
    "audio-classification",
    model="superb/wav2vec2-base-superb-er",
    device=-1
)

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 3) ì˜¤ë””ì˜¤ ë¡œë“œ & ëª¨ë…¸ + 16 kHz ë¦¬ìƒ˜í”Œë§
signal, sr = librosa.load(wav_path, sr=16000, mono=True)

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 4) í™”ìë³„ ê°ì • ì§‘ê³„ êµ¬ì¡°
speaker_emotion_counts = defaultdict(lambda: defaultdict(int))
speaker_emotion_probs  = defaultdict(list)

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 5) ì„¸ê·¸ë¨¼íŠ¸ë³„ ì¸ì‹ & í™”ì ë§¤í•‘
for idx, seg in enumerate(speech_timeline, 1):
    # 5-1) í™”ì ë§¤í•‘ (ê²¹ì¹œ ì‹œê°„ë§Œí¼ ê³„ì‚°)
    overlaps = {}
    for turn, _, spk in diar_result.itertracks(yield_label=True):
        overlap = max(0, min(turn.end, seg.end) - max(turn.start, seg.start))
        if overlap > 0:
            overlaps[spk] = overlap
    speaker = max(overlaps, key=overlaps.get) if overlaps else "UNKNOWN"

    # 5-2) ì˜¤ë””ì˜¤ ìŠ¬ë¼ì´ìŠ¤
    start_sample = int(seg.start * sr)
    end_sample   = int(seg.end   * sr)
    chunk        = signal[start_sample:end_sample]

    # 5-3) top_k=3 í›„ë³´ ê°ì • ë¶„ë¥˜
    results = clf(chunk, sampling_rate=sr, top_k=3)

    # 5-4) top1 ë¹ˆë„ ì¹´ìš´íŠ¸
    top1 = results[0]["label"]
    speaker_emotion_counts[speaker][top1] += 1

    # 5-5) í›„ë³´ ì ìˆ˜ ì €ì¥
    speaker_emotion_probs[speaker].append(results)

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 6) í™”ìë³„ ëˆ„ì  í™•ë¥  ê³„ì‚°
speaker_prob_sum = defaultdict(lambda: defaultdict(float))
for spk, seg_results in speaker_emotion_probs.items():
    for results in seg_results:
        for r in results:
            speaker_prob_sum[spk][r["label"]] += r["score"]

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 7) ê²°ê³¼ ì¶œë ¥

# 7-1) ë‹¨ìˆœ ë¹ˆë„ ê¸°ë°˜ ë¶„í¬
print("\nğŸ­ í™”ìë³„ top1 ê°ì • ë¶„í¬ (ë¹ˆë„)\n")
for spk, emo_cnt in speaker_emotion_counts.items():
    total = sum(emo_cnt.values())
    print(f"ğŸ”ˆ {spk} (ì´ ì„¸ê·¸ë¨¼íŠ¸: {total})")
    for label, cnt in emo_cnt.items():
        pct = cnt / total * 100
        print(f"  â€¢ {label:<8}: {cnt}ê°œ ({pct:.1f}%)")
    print()

# 7-2) ì„¸ê·¸ë¨¼íŠ¸ë³„ í›„ë³´ & ì ìˆ˜
print("ğŸ” ì„¸ê·¸ë¨¼íŠ¸ë³„ ê°ì • í›„ë³´ (top3)\n")
for spk, seg_results in speaker_emotion_probs.items():
    print(f"ğŸ”ˆ {spk}:")
    for i, results in enumerate(seg_results, 1):
        candidates = ", ".join(f"{r['label']}({r['score']:.2f})" for r in results)
        print(f"  â€¢ ì„¸ê·¸ë¨¼íŠ¸ {i}: {candidates}")
    print()

# 7-3) ëˆ„ì  í™•ë¥  ê¸°ë°˜ ë¶„í¬
print("ğŸ“Š í™”ìë³„ ëˆ„ì  í™•ë¥  ë¶„í¬\n")
for spk, prob_dict in speaker_prob_sum.items():
    total_score = sum(prob_dict.values())
    print(f"ğŸ”ˆ {spk}:")
    for label, score in prob_dict.items():
        pct = score / total_score * 100
        print(f"  â€¢ {label:<8}: ì´ì ={score:.2f}  ({pct:.1f}%)")
    print()

'''
ğŸ­ í™”ìë³„ top1 ê°ì • ë¶„í¬ (ë¹ˆë„)

ğŸ”ˆ SPEAKER_00 (ì´ ì„¸ê·¸ë¨¼íŠ¸: 1)
  â€¢ neu     : 1ê°œ (100.0%)

ğŸ” ì„¸ê·¸ë¨¼íŠ¸ë³„ ê°ì • í›„ë³´ (top3)

ğŸ”ˆ SPEAKER_00:
  â€¢ ì„¸ê·¸ë¨¼íŠ¸ 1: neu(0.95), hap(0.05), sad(0.00)

ğŸ“Š í™”ìë³„ ëˆ„ì  í™•ë¥  ë¶„í¬

ğŸ”ˆ SPEAKER_00:
  â€¢ neu     : ì´ì =0.95  (94.7%)
  â€¢ hap     : ì´ì =0.05  (5.1%)
  â€¢ sad     : ì´ì =0.00  (0.2%)
'''

'''
ë¹ˆë„(top1): ê° ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ ê°€ì¥ ìì‹  ìˆëŠ” ê°ì •ë§Œ ë‹¨ìˆœ ì„¸ê¸°
í›„ë³´(top3): í•œ êµ¬ê°„ ì•ˆì—ì„œ ëª¨ë¸ì´ ë³¸ ì„¸ ê°€ì§€ ê°€ëŠ¥ì„±ê³¼ í™•ë¥ 
ëˆ„ì  í™•ë¥ : ëª¨ë“  í›„ë³´ í™•ë¥ ì„ í•©ì‚°í•´, ì—¬ëŸ¬ êµ¬ê°„ì— ê±¸ì¹œ ê°ì • ë¶„í¬ë¥¼ ë¶€ë“œëŸ½ê²Œ í‘œí˜„
'''